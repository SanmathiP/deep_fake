# Fake it till you can't make it: A sneak peak to DeepFake Detection using just images #

## An experimental go through for detecting Deepfake videos as well images by utilizing the modalities generated by Inverserendernet++ network. ##

***

This project tries to tackle the problem of DeepFake detection (for both image and videos) by breaking them into modalities generated by Inverserendernet++ network. The workflow is summarized below.

- Break video into exactly 5 frames/images. (Not necessary for doing image based deepfake detection.)
- For each image generate the 5 modalities using the Inverserendernet Network.
- At this time we trained two types of network: simple classification network with single modality as input (and) ensemble network which takes all the modalities as input to classify as real/fake.
- For images the modality based ensemble is as good as the normal RGB based. 

***

## Architecture ##

To be added!!

## Usage ##

The project is heavily built on the InverseRenderNet++ implementaion. 
- To start off clone their repository from here: https://github.com/YeeU/InverseRenderNet_v2. 
- You also need to download the pretrained weights from here: https://drive.google.com/uc?export=download&id=1hGIoK3Pemtg3eYjFy_CBK-R37D3gA0VC and unzip it. 
- After cloning the repository , downloading and unzipping the pretrained weights the project structure would look like this:
```bash
InverseRenderNet_v2
│   README.md
│   test.py    
│   ...
|
└─────model_ckpt
│        model.ckpt.meta
│        model.ckpt.index
│        ...
└─────iiw_model_ckpt
│        model.ckpt.meta
│        model.ckpt.index
│        ...
└─────diode_model_ckpt
│        model.ckpt.meta
│        model.ckpt.index
│        ...
```
